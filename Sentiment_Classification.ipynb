{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing relevant libraries that will be used throughout this project:"
      ],
      "metadata": {
        "id": "7YQ5TvJwMKfN"
      },
      "id": "7YQ5TvJwMKfN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd9f64c",
      "metadata": {
        "id": "6cd9f64c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import nltk\n",
        "import pickle\n",
        "import natsort\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from os import listdir\n",
        "from pathlib import Path\n",
        "from sklearn import tree\n",
        "from PIL import ImageFile\n",
        "from nltk.corpus import stopwords\n",
        "from pytesseract import pytesseract\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc830440",
      "metadata": {
        "id": "bc830440"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "path_to_tesseract = r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bc2552",
      "metadata": {
        "id": "f4bc2552"
      },
      "source": [
        "### Pre-processing of text dataset:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593a1737",
      "metadata": {
        "id": "593a1737",
        "outputId": "44025312-a1b8-4372-8021-727f0255635d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>overall_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.JPG</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6987</th>\n",
              "      <td>6987</td>\n",
              "      <td>image_6988.jpg</td>\n",
              "      <td>Tuesday is Mardi Gras Wednesday is Valentine's...</td>\n",
              "      <td>Tuesday is Mardi Gras Wednesday is Valentine's...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6988</th>\n",
              "      <td>6988</td>\n",
              "      <td>image_6989.jpg</td>\n",
              "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...</td>\n",
              "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6989</th>\n",
              "      <td>6989</td>\n",
              "      <td>image_6990.png</td>\n",
              "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...</td>\n",
              "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990</th>\n",
              "      <td>6990</td>\n",
              "      <td>image_6991.jpg</td>\n",
              "      <td>When I VERY have time is a fantasy No one has ...</td>\n",
              "      <td>When I have time is a fantasy. no one has time...</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6991</th>\n",
              "      <td>6991</td>\n",
              "      <td>image_6992.jpg</td>\n",
              "      <td>The starting point for every good idea is \"Wha...</td>\n",
              "      <td>The starting point for every good idea is \"Wha...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6992 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0      image_name  \\\n",
              "0              0     image_1.jpg   \n",
              "1              1    image_2.jpeg   \n",
              "2              2     image_3.JPG   \n",
              "3              3     image_4.png   \n",
              "4              4     image_5.png   \n",
              "...          ...             ...   \n",
              "6987        6987  image_6988.jpg   \n",
              "6988        6988  image_6989.jpg   \n",
              "6989        6989  image_6990.png   \n",
              "6990        6990  image_6991.jpg   \n",
              "6991        6991  image_6992.jpg   \n",
              "\n",
              "                                               text_ocr  \\\n",
              "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
              "1     The best of #10 YearChallenge! Completed in le...   \n",
              "2     Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
              "3                 10 Year Challenge - Sweet Dee Edition   \n",
              "4     10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
              "...                                                 ...   \n",
              "6987  Tuesday is Mardi Gras Wednesday is Valentine's...   \n",
              "6988  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...   \n",
              "6989  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...   \n",
              "6990  When I VERY have time is a fantasy No one has ...   \n",
              "6991  The starting point for every good idea is \"Wha...   \n",
              "\n",
              "                                         text_corrected overall_sentiment  \n",
              "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...     very_positive  \n",
              "1     The best of #10 YearChallenge! Completed in le...     very_positive  \n",
              "2     Sam Thorne @Strippin ( Follow Follow Saw every...          positive  \n",
              "3                 10 Year Challenge - Sweet Dee Edition          positive  \n",
              "4     10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...           neutral  \n",
              "...                                                 ...               ...  \n",
              "6987  Tuesday is Mardi Gras Wednesday is Valentine's...           neutral  \n",
              "6988  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...           neutral  \n",
              "6989  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...          positive  \n",
              "6990  When I have time is a fantasy. no one has time...     very_positive  \n",
              "6991  The starting point for every good idea is \"Wha...          positive  \n",
              "\n",
              "[6992 rows x 5 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\labels.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608c988d",
      "metadata": {
        "id": "608c988d"
      },
      "outputs": [],
      "source": [
        "X = df.text_corrected\n",
        "df.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "senti = df['overall_sentiment']\n",
        "df.drop(['image_name', 'text_ocr'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7054148",
      "metadata": {
        "id": "a7054148"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(max_features = 1500, min_df = 5, max_df = 0.8)\n",
        "X = cv.fit_transform(X.apply(lambda x: np.str_(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb0cc9a",
      "metadata": {
        "id": "ccb0cc9a",
        "outputId": "40889cf5-4403-4847-beb8-c48f654d6968"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "positive         3127\n",
              "neutral          2201\n",
              "very_positive    1033\n",
              "negative          480\n",
              "very_negative     151\n",
              "Name: overall_sentiment, dtype: int64"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = {'very_positive': 1, 'positive': 1, 'neutral': 0, 'negative': -1, 'very_negative': -1}\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, senti.map(y), test_size = 0.25, random_state = 50)\n",
        "\n",
        "df['overall_sentiment'].value_counts()     #from here we find that our dataset is imbalanced!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "576432f9",
      "metadata": {
        "id": "576432f9",
        "outputId": "56d5ba44-d1a2-4160-8418-660434672c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training target statistics: Counter({-1: 3084, 1: 3084, 0: 3084})\n",
            "Testing target statistics: Counter({-1: 160, 0: 160, 1: 160})\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "over_sampler = RandomOverSampler(random_state = 45)\n",
        "X_res, y_res = over_sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "under_sampler = RandomUnderSampler(random_state = 45)\n",
        "X_tes, y_tes = under_sampler.fit_resample(X_test, y_test)\n",
        "\n",
        "print(f\"Training target statistics: {Counter(y_res)}\")\n",
        "print(f\"Testing target statistics: {Counter(y_tes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4dc1237",
      "metadata": {
        "id": "b4dc1237"
      },
      "source": [
        "### Training K-Neighbours Classifier (for text) & evaluating model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed89dd71",
      "metadata": {
        "id": "ed89dd71"
      },
      "outputs": [],
      "source": [
        "neigh_text = KNeighborsClassifier(metric = 'manhattan', n_neighbors = 30, weights = 'uniform')\n",
        "neigh_text = neigh_text.fit(X_res, y_res)\n",
        "y_pred = neigh_text.predict(X_tes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6771a81",
      "metadata": {
        "id": "b6771a81",
        "outputId": "fc5fec94-0546-4018-83be-58ad92566ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[ 46  96  18]\n",
            " [ 28 104  28]\n",
            " [ 37  92  31]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.29      0.34       160\n",
            "           0       0.36      0.65      0.46       160\n",
            "           1       0.40      0.19      0.26       160\n",
            "\n",
            "    accuracy                           0.38       480\n",
            "   macro avg       0.39      0.38      0.35       480\n",
            "weighted avg       0.39      0.38      0.35       480\n",
            "\n",
            "F1 score is: 0.35375458717060565\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_tes, y_pred))\n",
        "print(\"\\n\\n\", classification_report(y_tes, y_pred))\n",
        "print(\"F1 score is:\", f1_score(y_tes, y_pred, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e99669",
      "metadata": {
        "id": "91e99669"
      },
      "outputs": [],
      "source": [
        "pkl_filename1 = \"KNN_Text_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename1, 'wb') as file:\n",
        "    pickle.dump(neigh_text, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "387ebb4b",
      "metadata": {
        "id": "387ebb4b"
      },
      "source": [
        "## Training Decision Tree Classifier (for text) & evaluating model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6015995",
      "metadata": {
        "id": "b6015995"
      },
      "outputs": [],
      "source": [
        "clf_text = tree.DecisionTreeClassifier(criterion = 'entropy', splitter = 'random', random_state = 10, max_depth = 100,\n",
        "                                  class_weight = 'balanced', min_samples_split = 100, min_samples_leaf = 50)\n",
        "clf_text = clf_text.fit(X_res, y_res)\n",
        "y_pred = clf_text.predict(X_tes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310ab1da",
      "metadata": {
        "id": "310ab1da",
        "outputId": "d026ecb1-d792-4088-dfb4-5b7a4f4d6822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[72 68 20]\n",
            " [60 78 22]\n",
            " [62 72 26]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.45      0.41       160\n",
            "           0       0.36      0.49      0.41       160\n",
            "           1       0.38      0.16      0.23       160\n",
            "\n",
            "    accuracy                           0.37       480\n",
            "   macro avg       0.37      0.37      0.35       480\n",
            "weighted avg       0.37      0.37      0.35       480\n",
            "\n",
            "F1 score is: 0.3491827497179862\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_tes,y_pred))\n",
        "print(\"\\n\\n\", classification_report(y_tes,y_pred))\n",
        "print(\"F1 score is:\", f1_score(y_tes, y_pred, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b41b2c",
      "metadata": {
        "id": "69b41b2c"
      },
      "outputs": [],
      "source": [
        "pkl_filename2 = \"Decision_Tree_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename2, 'wb') as file:\n",
        "    pickle.dump(clf_text, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a550489e",
      "metadata": {
        "id": "a550489e"
      },
      "source": [
        "## Training Logistic Regression model (for text) & evaluating:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d28ecb8",
      "metadata": {
        "id": "6d28ecb8"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegression(C = 0.01, penalty = 'l2', solver = 'liblinear', random_state = 10).fit(X_res, y_res)\n",
        "y_pred = LR.predict(X_tes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceff77a8",
      "metadata": {
        "id": "ceff77a8",
        "outputId": "d3f384ee-0e2b-48ad-9a52-5cae2beae8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[51 53 56]\n",
            " [51 61 48]\n",
            " [40 51 69]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.32      0.34       160\n",
            "           0       0.37      0.38      0.38       160\n",
            "           1       0.40      0.43      0.41       160\n",
            "\n",
            "    accuracy                           0.38       480\n",
            "   macro avg       0.38      0.38      0.38       480\n",
            "weighted avg       0.38      0.38      0.38       480\n",
            "\n",
            "F1 score is: 0.3758491247232969\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_tes,y_pred))\n",
        "print(\"\\n\\n\", classification_report(y_tes,y_pred))\n",
        "print(\"F1 score is:\", f1_score(y_tes, y_pred, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7694d92",
      "metadata": {
        "id": "f7694d92"
      },
      "outputs": [],
      "source": [
        "pkl_filename3 = \"Logistic_Regression_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename3, 'wb') as file:\n",
        "    pickle.dump(LR, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6a96ed6",
      "metadata": {
        "id": "d6a96ed6"
      },
      "source": [
        "### Pre-processing of images dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e1b8a0",
      "metadata": {
        "id": "48e1b8a0"
      },
      "outputs": [],
      "source": [
        "from skimage import color\n",
        "from skimage.io import imread\n",
        "from skimage.feature import hog\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9294f81a",
      "metadata": {
        "id": "9294f81a"
      },
      "outputs": [],
      "source": [
        "file = []\n",
        "folder_dir = \"C:/Users/user/Desktop/Project/images\"\n",
        "\n",
        "for images in os.listdir(folder_dir):\n",
        "    file.append(images)\n",
        "\n",
        "file = natsort.natsorted(file) #to sort images according to their numbers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb177fdf",
      "metadata": {
        "id": "eb177fdf"
      },
      "outputs": [],
      "source": [
        "col = ['Fd', 'overall_sentiment']\n",
        "df2 = pd.DataFrame(columns = col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99c85a1",
      "metadata": {
        "id": "b99c85a1"
      },
      "outputs": [],
      "source": [
        "for i in range(len(file)):\n",
        "\n",
        "    imag_pth = r\"C:\\Users\\user\\Desktop\\Project\\images\\{}\".format(file[i])\n",
        "    img = imread(imag_pth)\n",
        "\n",
        "    try:\n",
        "        nx, ny, nrgb = img.shape\n",
        "\n",
        "    except:\n",
        "        img = color.gray2rgb(img)\n",
        "        nx, ny, nrgb= img.shape\n",
        "\n",
        "    x_train2 = img.reshape(nx, ny, nrgb)\n",
        "    resized_img = resize(x_train2, (128*4, 64*4))\n",
        "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                        cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
        "\n",
        "    df2 = df2.append({'Fd': fd, 'overall_sentiment': senti[i]}, ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236cb808",
      "metadata": {
        "id": "236cb808",
        "outputId": "79e74281-de68-4267-f757-9886df6c2ae5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fd</th>\n",
              "      <th>overall_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.16246362069040354, 0.08444857285499856, 0.0...</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.4695715440209436, 0.007319040344629182, 0.0...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.2769939213359277, 0.08707085859377085, 0.03...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.022272748396145056, 0.0, 0.0059946661863631...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6987</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6988</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6989</th>\n",
              "      <td>[0.042786180791997454, 0.0, 0.0307012700991192...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6990</th>\n",
              "      <td>[0.46689913471269245, 0.09902658307625116, 0.0...</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6991</th>\n",
              "      <td>[0.05675718185817567, 0.048060994178186565, 0....</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6992 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Fd overall_sentiment\n",
              "0     [0.16246362069040354, 0.08444857285499856, 0.0...     very_positive\n",
              "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     very_positive\n",
              "2     [0.4695715440209436, 0.007319040344629182, 0.0...          positive\n",
              "3     [0.2769939213359277, 0.08707085859377085, 0.03...          positive\n",
              "4     [0.022272748396145056, 0.0, 0.0059946661863631...           neutral\n",
              "...                                                 ...               ...\n",
              "6987  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           neutral\n",
              "6988  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           neutral\n",
              "6989  [0.042786180791997454, 0.0, 0.0307012700991192...          positive\n",
              "6990  [0.46689913471269245, 0.09902658307625116, 0.0...     very_positive\n",
              "6991  [0.05675718185817567, 0.048060994178186565, 0....          positive\n",
              "\n",
              "[6992 rows x 2 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.to_csv(\"Image_Fd.csv\")\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "905fa941",
      "metadata": {
        "id": "905fa941"
      },
      "outputs": [],
      "source": [
        "X_pic = df2.Fd\n",
        "senti_pic = df2['overall_sentiment']\n",
        "y_pic = {'very_positive': 1, 'positive': 1, 'neutral': 0, 'negative': -1, 'very_negative': -1}\n",
        "X_train_pic, X_test_pic, y_train_pic, y_test_pic = train_test_split(X_pic, senti_pic.map(y_pic),\n",
        "                                                                    test_size = 0.2, random_state = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c516d2",
      "metadata": {
        "id": "80c516d2"
      },
      "source": [
        "### Training Decision Tree Classifier (**for images**) & evaluating model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a552c05",
      "metadata": {
        "id": "9a552c05"
      },
      "outputs": [],
      "source": [
        "clf_img = tree.DecisionTreeClassifier(criterion = 'entropy', splitter = 'random', random_state = 10, max_depth = 100,\n",
        "                                      min_samples_split = 100, min_samples_leaf = 50)\n",
        "clf_img = clf_img.fit(list(X_train_pic), y_train_pic)\n",
        "y_pred_pic = clf_img.predict(list(X_test_pic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e06cc2",
      "metadata": {
        "id": "a2e06cc2",
        "outputId": "647996ee-7867-41bc-ea6b-a79a835eefa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[  2  36  93]\n",
            " [  8 107 296]\n",
            " [ 13 221 623]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.09      0.02      0.03       131\n",
            "           0       0.29      0.26      0.28       411\n",
            "           1       0.62      0.73      0.67       857\n",
            "\n",
            "    accuracy                           0.52      1399\n",
            "   macro avg       0.33      0.33      0.32      1399\n",
            "weighted avg       0.47      0.52      0.49      1399\n",
            "\n",
            "F1 score is of: 0.322923241632919\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_test_pic, y_pred_pic))\n",
        "print(\"\\n\\n\", classification_report(y_test_pic, y_pred_pic))\n",
        "print(\"F1 score is of:\", f1_score(y_test_pic, y_pred_pic, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652abba9",
      "metadata": {
        "id": "652abba9"
      },
      "outputs": [],
      "source": [
        "pkl_filename4 = \"Decision_Tree_img_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename4, 'wb') as file:\n",
        "    pickle.dump(clf_img, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d468383",
      "metadata": {
        "id": "6d468383"
      },
      "source": [
        "### Training K-Neighbour Classifier (**for images**) & evaluating model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae3d99f",
      "metadata": {
        "id": "8ae3d99f"
      },
      "outputs": [],
      "source": [
        "neigh = KNeighborsClassifier(metric = 'manhattan', n_neighbors = 5)\n",
        "neigh = neigh.fit(list(X_train_pic), y_train_pic)\n",
        "y_pred_pic = neigh.predict(list(X_test_pic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4ff9fa",
      "metadata": {
        "id": "6e4ff9fa",
        "outputId": "2a75ec79-bced-4844-df27-7a47fbce08a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[  8  41  82]\n",
            " [ 24 120 267]\n",
            " [ 39 277 541]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.11      0.06      0.08       131\n",
            "           0       0.27      0.29      0.28       411\n",
            "           1       0.61      0.63      0.62       857\n",
            "\n",
            "    accuracy                           0.48      1399\n",
            "   macro avg       0.33      0.33      0.33      1399\n",
            "weighted avg       0.46      0.48      0.47      1399\n",
            "\n",
            "F1 score is:  0.32708029531191934\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_test_pic, y_pred_pic))\n",
        "print(\"\\n\\n\", classification_report(y_test_pic, y_pred_pic))\n",
        "print(\"F1 score is: \", f1_score(y_test_pic, y_pred_pic, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4ae428",
      "metadata": {
        "id": "fe4ae428"
      },
      "outputs": [],
      "source": [
        "pkl_filename5 = \"KNN_img_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename5, 'wb') as file:\n",
        "    pickle.dump(neigh, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f95f459",
      "metadata": {
        "id": "4f95f459"
      },
      "source": [
        "### Training Logistic Regression model (**for images**) & evaluating model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3057fcbc",
      "metadata": {
        "id": "3057fcbc"
      },
      "outputs": [],
      "source": [
        "LR_img = LogisticRegression(C = 0.01, penalty = 'l2', solver = 'liblinear', random_state = 10).fit(list(X_train_pic), y_train_pic)\n",
        "y_pred_pic = LR_img.predict(list(X_test_pic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61e6cf2",
      "metadata": {
        "id": "c61e6cf2",
        "outputId": "2f8d5804-fcd5-4b2a-be3c-fe5fabf1a0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[  1  24 106]\n",
            " [  0  95 316]\n",
            " [  2 171 684]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.01      0.01       131\n",
            "           0       0.33      0.23      0.27       411\n",
            "           1       0.62      0.80      0.70       857\n",
            "\n",
            "    accuracy                           0.56      1399\n",
            "   macro avg       0.43      0.35      0.33      1399\n",
            "weighted avg       0.51      0.56      0.51      1399\n",
            "\n",
            "F1 score of is: 0.32761975135618626\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_test_pic, y_pred_pic))\n",
        "print(\"\\n\\n\", classification_report(y_test_pic, y_pred_pic))\n",
        "print(\"F1 score of is:\", f1_score(y_test_pic, y_pred_pic, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11dcbc46",
      "metadata": {
        "id": "11dcbc46"
      },
      "outputs": [],
      "source": [
        "pkl_filename6 = \"Logistic_Regression_img_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename6, 'wb') as file:\n",
        "    pickle.dump(LR_img, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69be22f5",
      "metadata": {
        "id": "69be22f5"
      },
      "source": [
        "### Saving Text Models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6259c11c",
      "metadata": {
        "id": "6259c11c",
        "outputId": "e01e80da-36af-41f2-a183-8bd876b32df3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=30)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric='manhattan', n_neighbors=30)"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(pkl_filename1, 'rb') as file:\n",
        "    Pkl_KNN_img = pickle.load(file)\n",
        "\n",
        "Pkl_KNN_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a9913d",
      "metadata": {
        "id": "40a9913d",
        "outputId": "db2421f1-3611-4963-8107-1d9eff7910ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
              "                       max_depth=100, min_samples_leaf=50,\n",
              "                       min_samples_split=100, random_state=10,\n",
              "                       splitter=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;, criterion=&#x27;entropy&#x27;,\n",
              "                       max_depth=100, min_samples_leaf=50,\n",
              "                       min_samples_split=100, random_state=10,\n",
              "                       splitter=&#x27;random&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
              "                       max_depth=100, min_samples_leaf=50,\n",
              "                       min_samples_split=100, random_state=10,\n",
              "                       splitter='random')"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(pkl_filename2, 'rb') as file:\n",
        "    Pkl_decision_tree = pickle.load(file)\n",
        "\n",
        "Pkl_decision_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ba0136",
      "metadata": {
        "id": "23ba0136",
        "outputId": "fc65edf6-06bb-40b4-b270-1879f1ae5299"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, random_state=10, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, random_state=10, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=0.01, random_state=10, solver='liblinear')"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(pkl_filename3, 'rb') as file:\n",
        "    Pkl_logistic_regression = pickle.load(file)\n",
        "\n",
        "Pkl_logistic_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55fbd46f",
      "metadata": {
        "id": "55fbd46f"
      },
      "source": [
        "### Saving Image Models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f827c72",
      "metadata": {
        "id": "4f827c72",
        "outputId": "aaf12c1e-ae58-4ccc-ef31-786306e2950b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=10)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(random_state=10)"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(pkl_filename4, 'rb') as file:\n",
        "    Pkl_decision_tree_img = pickle.load(file)\n",
        "\n",
        "Pkl_decision_tree_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d816ff2d",
      "metadata": {
        "id": "d816ff2d",
        "outputId": "2aeb117c-ed71-4a92-d536-71ee2ab027ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(pkl_filename5, 'rb') as file:\n",
        "    Pkl_knn_img = pickle.load(file)\n",
        "\n",
        "Pkl_knn_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fa17cb1",
      "metadata": {
        "id": "8fa17cb1",
        "outputId": "4dc89142-4085-49d3-cbec-4c7a8e9c8f92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=10)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(multi_class='multinomial', random_state=10)"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(pkl_filename6, 'rb') as file:\n",
        "    Pkl_logistic_regression_img = pickle.load(file)\n",
        "\n",
        "Pkl_logistic_regression_img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0c4475",
      "metadata": {
        "id": "ef0c4475"
      },
      "source": [
        "### Applying voting classifier (**for text**) and ensembling trained models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33208b01",
      "metadata": {
        "id": "33208b01"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee91b861",
      "metadata": {
        "id": "ee91b861"
      },
      "outputs": [],
      "source": [
        "for_text = []\n",
        "for_text.append(('LR', LogisticRegression(C = 0.01, penalty = 'l2', solver = 'liblinear', random_state = 10)))\n",
        "for_text.append(('KNC', KNeighborsClassifier(metric = 'manhattan', n_neighbors = 30, weights = 'uniform')))\n",
        "for_text.append(('DTC', tree.DecisionTreeClassifier(random_state = 10, class_weight = 'balanced')))\n",
        "\n",
        "vot_hard = VotingClassifier(estimators = for_text, voting = 'hard')\n",
        "vot_hard.fit(X_res, y_res)\n",
        "y_pred = vot_hard.predict(X_tes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a24d08e",
      "metadata": {
        "id": "6a24d08e",
        "outputId": "3c2f184d-232a-48db-c05f-68bedfa2601f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[63 57 40]\n",
            " [46 70 44]\n",
            " [47 56 57]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.39      0.40       160\n",
            "           0       0.38      0.44      0.41       160\n",
            "           1       0.40      0.36      0.38       160\n",
            "\n",
            "    accuracy                           0.40       480\n",
            "   macro avg       0.40      0.40      0.40       480\n",
            "weighted avg       0.40      0.40      0.40       480\n",
            "\n",
            "F1 score of Voting Classifier is: 0.3952116613498505\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_tes,y_pred))\n",
        "print(\"\\n\\n\", classification_report(y_tes,y_pred))\n",
        "print(\"F1 score of Voting Classifier is:\", f1_score(y_tes, y_pred, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a28a2e",
      "metadata": {
        "id": "53a28a2e"
      },
      "outputs": [],
      "source": [
        "pkl_filename7 = \"Voting_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename7, 'wb') as file:\n",
        "    pickle.dump(vot_hard, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcdc2d91",
      "metadata": {
        "id": "bcdc2d91"
      },
      "source": [
        "### Applying voting classifier (**for images**) and ensembling trained models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e9eb5b",
      "metadata": {
        "id": "73e9eb5b"
      },
      "outputs": [],
      "source": [
        "for_image = []\n",
        "for_image.append(('DTC', tree.DecisionTreeClassifier(random_state = 10)))\n",
        "for_image.append(('KNC', KNeighborsClassifier(n_neighbors = 5)))\n",
        "for_image.append(('LR', LogisticRegression(multi_class = 'multinomial', random_state = 10)))\n",
        "\n",
        "vot_hard_img = VotingClassifier(estimators = for_image, voting = 'soft')\n",
        "vot_hard_img.fit(list(X_train_pic), y_train_pic)\n",
        "y_pred = vot_hard_img.predict(list(X_test_pic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ab22cb",
      "metadata": {
        "id": "94ab22cb",
        "outputId": "9adb9746-981e-4bca-bf3e-034eec7e5101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[  1  25  64]\n",
            " [ 10  82 227]\n",
            " [ 17 176 447]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.04      0.01      0.02        90\n",
            "           0       0.29      0.26      0.27       319\n",
            "           1       0.61      0.70      0.65       640\n",
            "\n",
            "    accuracy                           0.51      1049\n",
            "   macro avg       0.31      0.32      0.31      1049\n",
            "weighted avg       0.46      0.51      0.48      1049\n",
            "\n",
            "F1 score of Voting Classifier is: 0.3127135765744731\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix:\\n\\n\", confusion_matrix(y_test_pic,y_pred))\n",
        "print(\"\\n\\n\", classification_report(y_test_pic,y_pred))\n",
        "print(\"F1 score of Voting Classifier is:\", f1_score(y_test_pic, y_pred, average = \"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6225fc",
      "metadata": {
        "id": "ad6225fc"
      },
      "outputs": [],
      "source": [
        "pkl_filename8 = \"Voting_img_Classifier.pkl\"\n",
        "\n",
        "with open(pkl_filename8, 'wb') as file:\n",
        "    pickle.dump(vot_hard_img, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "344732db",
      "metadata": {
        "id": "344732db"
      },
      "source": [
        "### Printing overall F1 score (**for all** trained models):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68f93e0",
      "metadata": {
        "id": "d68f93e0",
        "outputId": "d1549261-89f3-4783-f034-894b0181ac22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall F1 score is: 0.34421666666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"Overall F1 score is:\", (35.37+34.92+37.58+33.19+32.71+32.76)/600)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}